# BFS(Breadth-First-Seach)

- 그래프를 탐색하는데 사용되는 대표적인 알고리즘
- 같은 레벨의 노드들을 모두 방문한 후에 다음 레벨의 노드들을 방문하는 방식
- 큐(Queue) 자료구조를 사용한다

**왜 Queue를 사용할까?**

- 큐는 먼저 들어온 요소가 먼저 나가는 (FIFO, First-In-Firsh-Out)구조이기 때문에 레벨 단위로 노드를 처리하는 데 적합.

### BFS의 동작

- 시작 노드를 큐에 넣고 방문 표시
- 인접한 노드중 반문하지 않은 노드를 모두 큐에 넣고 방문 표시, 모든 그래프를 탐색한다.

### DFS와의 차이

1. 탐색 순서
    - BFS: 너비 우선, 같은 레벨 노드 먼저 탐색 이후 다음 레벨 노드를 차례대로 탐색
    - DFS: 깊이 우선. 한 경로를 끝까지 탐색한 후, 다른 경로를 탐색
2. 자료구조
    - 큐(Queue) 사용 먼저 들어온 노드를 먼저 처리하기 위해 적합
    - 스택(Stack) 이나 재귀를 사용
3. 메모리
- BFS : 많은 메모리 필요 큐에 여러 레벨의 노드를 저장해야 하기 때문에 그래프 크기에 따라 메모리 사용량이 증가
- DFS : 상대적 적은 메모리 사용, 스택의 깊이가 그래프에 지름에 비례하다.
1. 사용사례
- BFS : 최단 경로 문제에 많이 사용, 최소 신장 트리 알고리즘 등에서 활용
- DFS : 그래프의 연결 여부를 확인 사용, 위상정렬, 강한 연결요소 알고리즘에서 활용

![img.png](image%2Fimg.png)

### 예시 코드

```java
// BFS 알고리즘
        public void BFS(int start) {
            boolean[] visited = new boolean[V];
            Queue<Integer> queue = new LinkedList<>();

            visited[start] = true;
            queue.add(start);

            while (!queue.isEmpty()) {
                int current = queue.poll();
                System.out.print(current + " ");

                for (int neighbor : adjList[current]) {
                    if (!visited[neighbor]) {
                        visited[neighbor] = true;
                        queue.add(neighbor);
                    }
                }
            }
        }
```



-----
### 추가

## 링크드리스트(연결리스트) 특징

1. 하나의 데이터가 다음 데이터를 가리키고 있는 구조
2. 데이터를 추가할 때 마다 동적으로 메모리를 할당하는 구조이기 때문에, 데이터 추가에 한계가 없다.

![img_1.png](image%2Fimg_1.png)

### 링크드리스트 데이터 삽입

## 동작

![img_2.png](image%2Fimg_2.png)

index 2에 데이터를 삽입하기 위해선, index 1에 위치한 데이터의 방향을 바꿔주어야 한다.

이전에 위치한 데이터를 삽입할 데이터를 가리키도록 바꿔주고,

삽입할 데이터는 원래자리에 있던 데이터를 가리키도록 바꿔준다.

## 성능: O(N)

순차리스트와는 다르게, 이후 데이터들을 뒤로 밀어줄 필요가 없다.

그러나, 삽입위치까지 가기위해 Head부터 데이터 참조를 하나씩 타고 가야 하기 때문에, 최악의 경우 가장 마지막 데이터까지 참조를 타고 가야 한다.

# 링크드리스트 데이터 삭제

### 동작

![img_3.png](image%2Fimg_3.png)

삭제할때도 마찬가지로 기존의 연결을 간단하게 바꿔주면 데이터가 삭제되는 원리 입니다. 데이터를 땡기거나 할 필요가 없다.

### 성능: O(N)

최악의 경우 가장 마지막 데이터를 삭제하는 경우. 마지막 데이터까지 참조를 타고가야 하기 때문에 O(N)

### 성능상 장단점

장점:

1. 데이터 갯수만큼만 메모리를 사용하니 메모리 효율적
단점:

1. 캐쉬 친화적이지 않다(왜)
    - 링크드리스트는 캐쉬 친화적이지 않은 이유?(중요)

      데이터를 추가할 때 마다, 동적으로 힙메모리를 할당해 참조한다. 따라서, 힙메모리에 여기저기 데이터주소가 분산될 확률이 높다.


2. 인덱스로 데이터에 접근할때도 O(N)이다
    - 인덱스 조회성능이 O(N)인 이유

      Head 부터 참조를 하나씩 타고가야 하기 때문



## 순차 리스트(배열로 구현한 리스트)

> 순차리스트: 배열 자료구조를 이용해 리스트를 구현
>

### 동작 이해

### 순차리스트 데이터 삽입

![img_4.png](image%2Fimg_4.png)

![img_5.png](image%2Fimg_5.png)

데이터를 추가하려면 기존데이터를 한칸씩 뒤로 밀어줘야 한다. 새로운 공간을 확보해야 하기 때문

"빅오 노테이션" 으로 표현한다고 했으니 "최악의 경우의 연산횟수를 데이터갯수 N으로 표현"

최악의 경우, 맨 앞에 데이터를 추가하기 위해, N개 데이터 모두를 뒤로 한칸씩 밀어야 한다.

따라서 삽입연산의 빅오노테이션은 O(N)

<aside>
💡 순차리스트 삽입 : O(N)

</aside>

### 순차리스트 데이터 삭제

![img_6.png](image%2Fimg_6.png)

맨 앞 데이터 하나를 삭제할 때, 기존의 모든 데이터를 앞으로 한칸씩 당겨줘야 한다. 따라서, 빅오노테이션으로 표현하자면 O(N)

<aside>
💡 순차리스트 삭제 : O(N)

</aside>

### 배열로 리스트를 구현했을때 자료구조로써 장단점 분석

삽입 → O(N)

삭제 → O(N)

특정 데이터 조회 → O(N)

인덱스로 조회 → O(1)

### 장점

1. "배열"로 구현하니까, 인덱스 조회가 매우 빠르다(왜)

- 배열의 인덱스 조회가 빠른 이유

  배열은 모든 데이터타입이 같고, 메모리에 연속적으로 위치해 있다. 따라서 인덱스를 통해 메모리주소를 O(1)에 계산해 접근할 수 있다.


2. 캐시 친화적이다(왜)

- 배열이 캐시 친화적인 이유

  배열은 데이터가 메모리공간에서 연속적으로 위치합니다. 따라서, 캐시의 공간 지역성 원리에 의해 조회시에 높은 성능을 가질 확률이 높다.


### 단점

1. "배열"로 구현하니까, 처음에 데이터공간을 미리 할당하고 동적으로 크기를 변경할 수 없다.

- 하지만, 실제 동적배열 사용시에는 이 단점이 사라진다

  동적배열에선 데이터 삽입/삭제시 동적으로 내부배열크기를 조절하는 방식으로 해당 단점을 없앴다.



## 자료구조가 캐시 친화적이다/친화적이지 않다

### 메모리에는 여러 단계가 있다

```java
int a = 4;
int b = a;
```

지금까지 메모리를 모두 RAM이라고 뭉뚱그려서만 표현 했었는데, 사실 메모리에는 여러 단계가 있다.
RAM 말고도 그것보다 훨씬 용량은 작지만 매우 빠른 단계가 있다.  → 캐시

CPU에서 모든 코드의 작동을 처리하는데, 캐시메모리는 CPU와 매우 가깝고 스피드가 가장 빠른 메모리따라서 RAM에서 한번 특정 메모리를 사용한다면, 그 메모리 주변을 캐시메모리에 적재.

만약 메인메모리의 이곳 저곳에 산발적으로 접근한다면, 캐시메모리에 이쪽부분을 다 담았다가 저쪽부분을 다 담았다가 등등의 동작을 하며 캐시메모리를 잘 쓸 수 없다.

하지만 가까운 메모리주소의 메모리들에 주로 접근한다면, 해당 메모리들은 함께 캐싱되어있을 확률이 높기 때문에 매우 빠르게 데이터를 가져올 수 있게 되는 것

![img_7.png](image%2Fimg_7.png)
![img_8.png](image%2Fimg_8.png)
